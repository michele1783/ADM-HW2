{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from functools import reduce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions\n",
    "Here we have defined all the useful functions to accomplish the request"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def orario(lista, time_col):\n",
    "    list_time = [datetime.strptime(t, '%H:%M:%S').time() for t in lista]\n",
    "    number_review = []\n",
    "    for i in range(0, len(list_time), 2):\n",
    "        number_review.append(len((time_col[(time_col >= list_time[i]) & (time_col <= list_time[i + 1])])))\n",
    "    xx = []\n",
    "    for i in range(0, len(list_time), 2):\n",
    "        xx.append(str(list_time[i].hour))\n",
    "    #xx = ['6am', '11am', '2pm', '5pm', '8pm', '12am', '3am']\n",
    "    plt.bar(xx, number_review, color = 'salmon')\n",
    "    plt.yscale('log')\n",
    "    plt.yticks([2000000, 2500000, 3000000, 3500000, 4000000])\n",
    "    plt.title('Number of review for each interval of time')\n",
    "    plt.xlabel('Intervals')\n",
    "    plt.ylabel('Number of review')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parsedate(time_as_a_unix_timestamp):\n",
    "    return pd.to_datetime(time_as_a_unix_timestamp, unit = 's')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filtro(data, lingue):\n",
    "    a = pd.DataFrame(columns = dataset.columns)\n",
    "    for i in range(len(lingue)):\n",
    "        a = pd.concat([a, data[data.language == lingue[i]]])\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the dataset\n",
    "we load our dataset and using the function **parsedate** we have changed the format of our timestamp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('steam_reviews.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('steam_reviews.csv', header='infer',\n",
    "parse_dates=['timestamp_created',\n",
    "'timestamp_updated', 'author.last_played'],\n",
    "date_parser = parsedate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Exploratory Data Analysis (EDA)\n",
    "\n",
    "To try to better understand our dataset we have made a bunch of plots and tables in which we have tried to catch some information about these reviews received for the applications in Steam."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Application more reviewed: \n",
    "To start our analysis we have made a pie chart about applications more reviewed. In particular we have decided to pick the first thirty games more reviewed and understand how the number of rewiews is splitted between them. Indeed the percentage written in the slices of the pie plot is referred not to the total number of reviews but the to the sum of reviews written for these thirty more popular games. The choice of thirty is due to make cleaner the plot and because we are interested only in the more popular games. The most talked-about."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = pd.Series(dataset.groupby(\"app_name\").app_id.count().sort_values(ascending=False).head(30))\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.pie(a,\n",
    "labels = a.index,\n",
    "explode = [0.1 for value in range(0, a.index.nunique())],\n",
    "shadow = True, autopct = '%.1f%%')\n",
    "plt.title('Application name', fontsize = 20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Correlation matrix:\n",
    "Then we have tried to make a correlation matrix to understand if there are some variables correlated between them "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,13)) \n",
    "sns.heatmap(dataset.corr(), cbar=True, annot = True, cmap='BrBG', linewidths=.3,fmt='.1g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have noticed that there was not any particular correlation between columns except for the ones related to time played by the player therefore we have decided to see in depth these correlations to have clearer information about them. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset,columns=['author.playtime_forever','author.playtime_last_two_weeks',\\\n",
    "                                   'author.playtime_at_review'])\n",
    "corrMatrix = df.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Time and Language:\n",
    "At this point we want to extract some information about the language of the reviews and time when they were written. We have divided the day in three parts: morning (8am-2pm), afternoon (2pm-10pm) and night (10pm-8am). \n",
    "So for each part of the day we have grouped the reviews by language, counted them and picked the ten languages more popular.\n",
    "\n",
    "In this way in our final barplot for each popular language we have the number of reviews written in each part of the day. We have also made a table to explain better the number obtained. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr_1 = np.array((dataset['timestamp_created'].dt.time.astype('str') >= \"08:00:00\")& (dataset['timestamp_created'].dt.time.astype('str') <= \"13:59:59\"))\n",
    "arr_2 = np.array((dataset['timestamp_created'].dt.time.astype('str') >= \"14:00:00\")& (dataset['timestamp_created'].dt.time.astype('str') <= \"21:59:59\"))\n",
    "arr_3 = np.array((dataset['timestamp_created'].dt.time.astype('str') >= \"22:00:00\")& (dataset['timestamp_created'].dt.time.astype('str') <= \"7:59:59\"))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mattina = pd.Series(dataset[arr_1].groupby(\"language\").language.count().sort_values(ascending=False).head(10))\n",
    "pomeriggio = pd.Series(dataset[arr_2].groupby(\"language\").language.count().sort_values(ascending=False).head(10))\n",
    "notte = pd.Series(dataset[arr_3].groupby(\"language\").language.count().sort_values(ascending=False).head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = mattina.to_frame(name = \"8am-2pm\")\n",
    "df[\"2pm-10pm\"]=pomeriggio\n",
    "df[\"10pm-8am\"]=notte\n",
    "df['language'] = df.index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index([\"language\"], drop = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = df.plot(x = \"language\", kind ='bar', stacked = False, figsize =(10,8), alpha=1, rot=0)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('languages')\n",
    "ax.set_ylabel(\"number reviews\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this stacked barplot we can see that the majority of the reviews are written during the afternoon while during the night fewer people usually write on Steam. The language more used as expected is English"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Viral Comments:\n",
    "In this table we have wanted to look at the ten reviews which have received more comments because we have thought that it could be interesting look at them to understand which comments are popular on Steam. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_7 = dataset.sort_values(by=['comment_count'], ascending = False)\n",
    "dataset_7 = dataset_7.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_7[[\"author.steamid\", \"language\", \"review\", \"comment_count\"]].head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately the majority of them are written not in english!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Games more played:\n",
    "In our dataset there is a column in which is stored the time played by that player to that particular game. So we have decided to explore what are the games more played in terms of hours. We have decided to pick the top 20 games because we have thought that 20 is a good trade-off between a clear plot and a meaningful number of games. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dataset_8 = dataset_8[[\"author.steamid\", \"author.playtime_forever\",\"app_name\"]]\n",
    "dataset_8 = pd.Series(dataset.groupby(\"app_name\")[\"author.playtime_forever\"].sum().sort_values(ascending=False))\n",
    "ore_di_gioco = dataset_8.values\n",
    "giochi = dataset_8.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = ((15, 8)))\n",
    "sns.barplot(x = ore_di_gioco[:20], \n",
    "            y = giochi[:20], orient = 'h')\n",
    "plt.title('TOP 20 games more played in terms of hours', size = 20)\n",
    "plt.ylabel('Games', size = 14, style = 'italic')\n",
    "plt.xlabel('Number of hours', size = 14, style = 'italic')\n",
    "#plt.xscale('log')\n",
    "plt.xticks(np.arange(1000000000,60000000000,2000000000)) \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this barplot we have found some confirms: the games more played are also often the games more reviewed that were appeared in the pie chart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Active players:\n",
    "To conclude this first analysis we have tried to understand what are the players more useful for Steam: we have selected the ten authors that have written the most number of helpful and funny reviews. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_9 = pd.Series(dataset[(dataset.votes_helpful > 0)].groupby(\"author.steamid\").votes_helpful.count().sort_values(ascending=False))\n",
    "\n",
    "dataset_10 = pd.Series(dataset[(dataset.votes_funny > 0)].groupby(\"author.steamid\").votes_funny.count().sort_values(ascending=False))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.concat([dataset_9[:11], dataset_10[:11]], axis=1).reset_index().fillna(0).sort_values(by=['votes_helpful'],ascending=False).reset_index(drop = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's interesting to see that the authors who have written some funny reviews have also written helpful reviews. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Languages and subplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"The total number of languages used to write reviews is \",'\\033[1m' +str(len(dataset[\"language\"].unique())) +'\\033[0m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making a subplot we have been able to visualize all the present languages in the dataset and counting the number of reviews. The two subplots have different measure in y-scales!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(25,18))\n",
    "ax1=fig.add_subplot(2,1,1)\n",
    "dataset['language'].value_counts().head(10).plot.bar(figsize = (18, 10),title='Top Languages',xlabel='Language',ylabel='Number of Reviews', ax = ax1,rot=0, logy = True, color = \"orange\")\n",
    "ax2=fig.add_subplot(2,1,2)\n",
    "dataset['language'].value_counts().iloc[-18:].plot.bar(figsize = (18, 10),title='Other Languages',xlabel='Language',ylabel='Number of Reviews', ax = ax2,rot=0, color = \"orchid\")\n",
    "fig.tight_layout();\n",
    "\n",
    "#dataset['language'].value_counts().plot.bar(figsize = (18, 7),title='Top Languages',xlabel='Language',ylabel='Number of Reviews', ax = ax1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of reviews for each application in descending order."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have decided to make a barplot in which we have counted the number of reviews for the first 50 applications. We have decided 50 because it have seemed to us a good tradeoff to have a clean representation a pick the more reviewed games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_review = dataset.groupby(\"app_name\").review_id.count().sort_values(ascending=False)\n",
    "number_review[0:51].plot.bar(figsize = (18, 7), title=' Number of review', xlabel='Name of application',\n",
    "ylabel='Number of review', color = \"coral\", logy = True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Best Weighted Vote Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each review has a **Weighted Vote Score** that represents the helpfuness score of that review. To extract the weighted  vote score for each game we have computed the mean between all the vote for each application. In this way we have an idea about what applications have received the most helpfulness reviews. Then we have decided to select only average votes above 0.3 because we have considered it a good threshold for the best votes.   "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "medie = pd.DataFrame(dataset.groupby(\"app_name\").weighted_vote_score.mean().sort_values(ascending=False))\n",
    "medie = medie[medie.values > 0.3]\n",
    "medie"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# *NEW*\n",
    "### Which applications have the most and the least recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Most\n",
    "# recommended. group_by app_name. count all recommended,\n",
    "# count True recommended and False recommended in separate cols, and percentage of these.\n",
    "# taking only the useful cols\n",
    "new_data = dataset[['app_name', 'recommended']]\n",
    "# count_rec col counts all recommended respectively False and True of an application\n",
    "new_data['count_rec'] = new_data.groupby(['app_name', 'recommended'], sort=False)['recommended'].transform('count')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_rec col counts all recommedations, False and True together\n",
    "new_data['all_rec'] = new_data.groupby(\"app_name\", sort=False)['count_rec'].transform('count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final dataframe which contains only the True recommendations\n",
    "# this means that we can calculate the most and the least recommended apps\n",
    "final = new_data[(new_data['recommended']==True)].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "final.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# perc_rec calculates the percentage recommendation\n",
    "final['perc_rec'] = (final['count_rec']/final['all_rec'])*100\n",
    "# drop not useful cols\n",
    "final.drop(['recommended', 'count_rec'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# most recommended, first 50\n",
    "final.sort_values(by='perc_rec', ascending=False).head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# least recommended, first 50\n",
    "final.sort_values(by='perc_rec', ascending=True).head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How many of these applications were purchased, and how many were given for free?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# steam_purchase\n",
    "# taking only the useful cols\n",
    "new_data1 = dataset[['app_name', 'steam_purchase']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data1.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same modus operandi of counting recommendation\n",
    "new_data1['count_pur'] = new_data1.groupby(['app_name', 'steam_purchase'], sort=False)['steam_purchase'].transform('count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data1.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taking only the ones purchased\n",
    "final1 = new_data1[(new_data1['steam_purchase']==True)].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "final1.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop not useful col\n",
    "final1.drop(['steam_purchase'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "final1.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# received_for_free\n",
    "# taking only the useful cols\n",
    "new_data2 = dataset[['app_name', 'received_for_free']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data2.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same modus operandi\n",
    "new_data2['count_free'] = new_data2.groupby(['app_name', 'received_for_free'], sort=False)['received_for_free'].transform('count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "new_data2.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take only the ones received_for_free\n",
    "final2 = new_data2[(new_data2['received_for_free']==True)].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "final2.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop not useful col\n",
    "final2.drop(['received_for_free'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first 20\n",
    "final2.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now it's time to calculate the final result, by doing a merge of the final dataframes\n",
    "dfs = [final, final1, final2]\n",
    "final_df = reduce(lambda  left,right: pd.merge(left,right,on=['app_name'],\n",
    "                                            how='outer'), dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorting the values in descending order\n",
    "final_df.sort_values(by='perc_rec', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taking the first 40 apps that are most recommended and displaying how many times were\n",
    "# purchased and how many times were received for free\n",
    "final_df.head(40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# *OLD*\n",
    "### Which applications have the most and the least recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just to start we have just selected the ten applications that have more and less number of positive recommendations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Most\n",
    "most = pd.DataFrame(dataset[(dataset.recommended == True)].groupby(\"app_name\").recommended.count().sort_values(ascending=False)).rename(columns={'recommended': 'positive rec'})\n",
    "most.iloc[:10]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Least\n",
    "most.iloc[-10:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After extracting the absolute values we have decided to compute the relative values of number of positive recommendations. We have done that computing for each application the ratio between positive recommendation and total number of reviews. This kind of operation have seemed more meaningful to us"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_recom = dataset.groupby('app_name')['recommended'].count().reset_index()\n",
    "\n",
    "positive_recom = dataset[(dataset.recommended == True)].groupby('app_name')['recommended'].count().reset_index()\n",
    "\n",
    "positive_recom = positive_recom.rename(columns={'app_name': 'app_name', 'recommended': 'rec_True'})\n",
    "\n",
    "dataset_12= positive_recom.merge(total_recom, left_on = 'app_name', right_on = 'app_name')\n",
    "\n",
    "dataset_12['percent_True'] = dataset_12['rec_True'] / dataset_12['recommended']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_12 = dataset_12.sort_values(by=[\"percent_True\"], ascending = False).reset_index(drop = True)\n",
    "\n",
    "most_2 = dataset_12.iloc[0:10]\n",
    "\n",
    "least_2 = dataset_12.iloc[-10:]\n",
    "\n",
    "most_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just to visualize this table we have made a plot in which we can see the ratio between positive recommendation and total recommendations of games and in addition we can have also an idea of their absolute value. Not all games have the same number of recommendations!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = most_2.plot(x = \"app_name\", y = [\"rec_True\", \"recommended\"], kind ='bar', stacked = False, figsize =(10,8), alpha=1, rot=90, color =[\"bisque\",\"limegreen\"])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('languages')\n",
    "ax.set_ylabel(\"number reviews\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "least_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We do the same kind of plot for games that have the smaller ratio between positive recommendation and total recommendation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = least_2.plot(x = \"app_name\", y = [\"rec_True\", \"recommended\"], kind ='bar', stacked = False, figsize =(10,8), alpha=1, rot=90, color = [\"lightblue\",\"purple\"])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('languages')\n",
    "ax.set_ylabel(\"number reviews\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that if we consider the absolute or relative value of positive recommendations we extract different games. When we consider the absolute value there are some games that have an high number of positive recommendations but also not positive ones so they are in the both list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How many of these applications were purchased, and how many were given for free?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among applications that have the major and the minor *relative* number of positive recommendations we have observed for each application the number of copies that are received for free and the one which are not. We have used only the column **received_for_free** because we have thought that if in this column there is a **True** the game is received for free if instead there is **False** the game is purchased.\n",
    "\n",
    "We have considered games that have more positive recommendations relative to their number of reviews and not considered games that have more positive recommendations in absolute value because we have thought that in this way the dataframe that we will obtain are more meaningful."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "most_1 = list(most_2.app_name)\n",
    "new_data = dataset[(dataset[\"app_name\"].isin(most_1))]\n",
    "pd.DataFrame(new_data.groupby([\"app_name\", \"received_for_free\"]).received_for_free.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "least_1 = list(least_2.app_name)\n",
    "new_data_2 = dataset[(dataset[\"app_name\"].isin(least_1))]\n",
    "pd.DataFrame(new_data_2.groupby([\"app_name\", \"received_for_free\"]).received_for_free.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#new_data[new_data.received_for_free == True].groupby(\"app_name\").received_for_free.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Most\n",
    "#most_1 = list(most.index)\n",
    "#new_data = new_data[(new_data[\"app_name\"].isin(most_1))]\n",
    "#pd.DataFrame(new_data.groupby([\"app_name\", \"received_for_free\"]).recommended.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Least\n",
    "#least_1 = list(least.index)\n",
    "#new_data1 = new_data1[(new_data1[\"app_name\"].isin(least_1))]\n",
    "#pd.DataFrame(new_data1.groupby([\"app_name\", \"received_for_free\"]).recommended.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is the most common time that authors review an application? For example, authors usually write a review at 17:44."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first point\n",
    "# taking only the timestamp_created col\n",
    "timestamp_col = np.array(dataset[\"timestamp_created\"].dt.time.astype('str'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_time = {}\n",
    "for time in timestamp_col:\n",
    "    # taking only hour and minute\n",
    "    new_time = time[:5]\n",
    "    if new_time not in list(dict_time.key()):\n",
    "        dict_time[new_time] = 1\n",
    "    else:\n",
    "        dict_time[new_time] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorting the dictionary in descending order\n",
    "dict_time_sorted = {k: v for k, v in sorted(dict_time.items(), key=lambda item: item[1], reverse=True)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# returning the most common time (without seconds)\n",
    "next(iter(dict_time_sorted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the function **orario** we can extract for a given list of time interval the number of reviews written in each time interval "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intervalli = ['06:00:00', '10:59:59', '11:00:00', '13:59:59', '14:00:00', '16:59:59',\n",
    "        '17:00:00', '19:59:59', '20:00:00', '23:59:59', '00:00:00', '02:59:59', '03:00:00',\n",
    "        '05:59:59']\n",
    "timestamp_col1 = np.array(dataset[\"timestamp_created\"].dt.time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orario(intervalli, timestamp_col1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the x-axis for each bar is indicated the starting point of the time interval. We have observed that fewer people have written reviews during the night while the majority of people have written their reviews in the first hours of the morning and in the dinner hours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What are the top 3 languages used to review applications?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_languages = pd.DataFrame(dataset.groupby(\"language\").review_id.count().sort_values(ascending=False).head(3))\n",
    "top_languages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected the majority of the reviews are written in english, chinese and russian!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_languages = list(top_languages.index)\n",
    "top_languages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a function that receives as parameters both the name of a data set and a list of languages’ names and returns a data frame filtered only with the reviews written in the provided languages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There we have used the function **filtro** to accomplish a dataframe where there are only reviews written in the top 3 languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_filter = filtro(dataset, top_languages)\n",
    "dataset_filter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the function created in the previous literal to find what percentage of these reviews (associated with the top 3 languages) were voted as funny?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this request we have used the new filtered dataset and for each language we have selected the reviews that have received at least one funny vote and then we have computed the ratio between them and all the reviews written in that language.\n",
    "\n",
    "To compute this percentage we have used **dataset_filter** that is the new dataframe obtained using the previous function **filtro**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numeratore = []\n",
    "denominatore = []\n",
    "rapporto = []\n",
    "for i in range(len(top_languages)):\n",
    "    numeratore.append(dataset_filter[(dataset_filter.votes_funny != 0) & (dataset_filter.language == top_languages[i])].votes_funny.count())\n",
    "    denominatore.append(dataset_filter[dataset_filter.language == top_languages[i]].votes_funny.count())\n",
    "    rapporto.append(round((numeratore[i]/denominatore[i])*100, 2))\n",
    "    print(\"The percentage of reviews written in \",'\\033[1m' +top_languages[i]+'\\033[0m',\" that has received at least a funny vote is \"'\\033[1m' +str(rapporto[i])+\"%\"+'\\033[0m')\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point we have also wanted to compute the percentage of reviews that have received at least a funny vote among all these three languages. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = dataset_filter[dataset_filter.votes_funny != 0].votes_funny.count()\n",
    "den = dataset_filter.votes_funny.count()\n",
    "print(\"The percentage of reviews written in one of the top 3 language that has received at least a funny vote is \", '\\033[1m' +str(round((num/den)*100, 2))+\"%\"+'\\033[0m')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the function created in the literal “a” to find what percentage of these reviews (associated with the top 3 languages) were voted as helpful?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this request we have used the new filtered dataset and for each language we have selected the reviews that have received at least one helpful vote and then we have computed the ratio between them and all the reviews written in that language.\n",
    "\n",
    "To compute this percentage we have used **dataset_filter** that is the new dataframe obtained using the previous function **filtro**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numeratore = []\n",
    "denominatore = []\n",
    "rapporto = []\n",
    "for i in range(len(top_languages)):\n",
    "    numeratore.append(dataset_filter[(dataset_filter.votes_helpful != 0) & (dataset_filter.language == top_languages[i])].votes_helpful.count())\n",
    "    denominatore.append(dataset_filter[dataset_filter.language == top_languages[i]].votes_helpful.count())\n",
    "    rapporto.append(round((numeratore[i]/denominatore[i])*100, 2))\n",
    "    print(\"The percentage of reviews written in \",'\\033[1m' +top_languages[i]+\"%\"+'\\033[0m'+ \" that has received at least a helpful vote is \",'\\033[1m' +str(rapporto[i])+\"%\"+'\\033[0m'+\"%\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point we have also wanted to compute the percentage of reviews that have received at least a helpful vote among all these three languages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = dataset_filter[dataset_filter.votes_helpful != 0].votes_helpful.count()\n",
    "den = dataset_filter.votes_helpful.count()\n",
    "print(\"The percentage of reviews written in one of the top 3 language that has received at least a helpful vote is \", '\\033[1m' +str(round((num/den)*100, 2))+\"%\"+'\\033[0m')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ6 \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is the average time (days and minutes) a user lets pass before he updates a review?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just to start we have computed the difference between the time when the review is written and time when the review is updated and then we have transformed this difference in terms of days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['Difference_Days'] = (dataset['timestamp_updated'] - dataset['timestamp_created'])\n",
    "dataset['Difference_Days'] = dataset['Difference_Days']/np.timedelta64(1,'D')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After that we have deleted who did not update his review because we have thought that is meaningless consider them. Then we have computed the mean between days and the integer part of this number represents the average number of days after an author updates his review. Instead to transform the decimal part in minutes we have to multiply it for 1440 because in one day there are 1440 minutes. We have made a simple proportion: *1 : 1440 = x : (decimal part of our number)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_1 = dataset[dataset.Difference_Days != 0]\n",
    "average = dataset_1.Difference_Days.mean()\n",
    "minutes = round((average % 1) * 1440, 0)\n",
    "days = average // 1\n",
    "print(\"The average time a user lets pass before he updates a review is \",'\\033[1m' +str(days)+'\\033[0m' +\" days and \",'\\033[1m' +str(minutes)+'\\033[0m' +\" minutes\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On average an author updates his review almost after a year! "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot the top 3 authors that usually update their reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have used the dataframe **dataset_1** in which there are only the reviews that have been updated. We did not use the starting dataset because we have to extract who are the authors that usually update their reviews so authors that have updated more reviews through time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = pd.Series(dataset_1.groupby('author.steamid').review_id.count().sort_values(ascending=False).head(3))\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = a.plot(kind=\"bar\", color = [\"orchid\", \"orange\", \"green\"], alpha=0.75, rot=0)\n",
    "ax.set_title(\"TOP 3 authors that have updated more reviews\")\n",
    "ax.set_xlabel(\"Steam ID\")\n",
    "ax.set_ylabel(\"Number of reviews updated\")\n",
    "labels = list(a.values)\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(\n",
    "        rect.get_x() + rect.get_width() / 2, height + 1, label, ha=\"center\", va=\"bottom\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have put the number of reviews over the bars because the second and the third author have updated almost the same number of reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ7\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What’s the probability that a review has a Weighted Vote Score equal to or bigger than 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have used the definition of probability to compute these values indeed we have count the number of reviews that has a Weighted Vote Score equal to or bigger than 0.5 and this number represents the favourable case (we have stored this number in **casi_fav**)while the number of total case is represented by the number of the lines of our dataset, stored in **casi_tot**. The probability is the ratio between them. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "casi_fav = dataset[dataset.weighted_vote_score >= 0.5].weighted_vote_score.count()\n",
    "casi_fav"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "casi_tot = dataset.weighted_vote_score.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_1 = round(casi_fav/casi_tot, 2)\n",
    "print(\"The probability is of a review has a Weighted Vote Score equal to or bigger than 0.5 is \"+ '\\033[1m' +str(result_1)+'\\033[0m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What’s the probability that a review has at least one vote as funny given that the Weighted Vote Score is bigger than 0.5?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To compute this conditional probability my sample sample will be reduced indeed we have filtered the dataset in such way that we are going to look for reviews with at least one vote as funny just among reviews with Weighted Vote Score is bigger than 0.5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_prob = dataset[dataset.weighted_vote_score > 0.5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "casi_fav_2 = dataset_prob[dataset_prob.votes_funny != 0].votes_funny.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our sample space in other words the total case are the favourable case used to compute the last probability, **case_fav**: number of reviews that has a Weighted Vote Score equal to or bigger than 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_2 = round(casi_fav_2/casi_fav, 2)\n",
    "print(\"The conditional probability that a review has at least one vote as funny given that the Weighted Vote Score is bigger than 0.5 is \",'\\033[1m' +str(result_2)+'\\033[0m')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Is the probability that “a review has at least one vote as funny” independent of the “probability that a review has a Weighted Vote Score equal or bigger than 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To be independent these two events it would happen that the probability of the event: *a review has at least one vote as funny* would be equal to *probability that a review has at least one vote as funny given that the Weighted Vote Score is bigger than 0.5* because in this way the conditioning of the two probability is useless given that they are independent. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "casi_fav_3 = dataset[dataset.votes_funny != 0].votes_funny.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_3 = round(casi_fav_3/casi_tot,2)\n",
    "print(\"The probability of a review has at least one vote as funny is \"+ '\\033[1m' +str(result_3)+'\\033[0m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.12 is different from 0.24 so these two events are **dependent!**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}